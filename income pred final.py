# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VsIbjrp2NZvNZCGMcvVMW3gFpUnCyimL
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

path = ('drive/My Drive/ML Kaggle Group')

import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
import numpy as np

train = pd.read_csv("/content/drive/My Drive/ML Kaglle Group/tcd-ml-1920-group-income-train.csv",index_col=None) 
sub_test = pd.read_csv("/content/drive/My Drive/ML Kaglle Group/tcd-ml-1920-group-income-test.csv",index_col=None)
submission = pd.read_csv("/content/drive/My Drive/ML Kaglle Group/tcd-ml-1920-group-income-submission.csv",index_col=None)

data = pd.concat([train,sub_test],ignore_index=True)

data = data.replace('nA',np.nan)

def process_satisfaction(dataset):
  dataset['Satisfation with employer'].replace(np.nan, 'Missing', inplace=True)
def process_exp(dataset):
  median = dataset[dataset['Work Experience in Current Job [years]']!='#NUM!']['Work Experience in Current Job [years]'].median()
  dataset['Work Experience in Current Job [years]'].replace('#NUM!', median, inplace=True)
def process_housing(dataset):
  dataset['Housing Situation'].replace('0', 'Missing', inplace=True)
  dataset['Housing Situation'].replace(np.nan, 'Missing', inplace=True)

def process_hair_color(dataset):
    dataset['Hair Color'].replace('0', 'Missing', inplace=True)
    dataset['Hair Color'].replace('unknown', 'Missing', inplace=True)
    dataset['Hair Color'].replace(np.nan, 'Missing', inplace=True)


def process_university_degree(dataset):
    dataset['University Degree'].replace(np.nan, 'Missing', inplace=True)


def process_profession(dataset):
    dataset['Profession'].replace(np.nan, 'Missing', inplace=True)


def process_year_of_record(dataset):
    year_median = dataset['Year of Record'].median()
    dataset['Year of Record'].replace(np.nan, year_median, inplace=True)


def process_age(dataset):
    age_median = dataset['Age'].median()
    dataset['Age'].replace(np.nan, age_median, inplace=True)
    dataset['Age'] = (dataset['Age'] * dataset['Age']) ** (0.5)


def process_gender(dataset):
    dataset['Gender'].replace('f', 'female', inplace=True)
    dataset['Gender'].replace('0', 'Missing', inplace=True)
    dataset['Gender'].replace('other', 'Missing', inplace=True)
    dataset['Gender'].replace('unknown', 'Missing', inplace=True)
    dataset['Gender'].replace(np.nan, 'Missing', inplace=True)

def preprocess_dataset(dataset):
    process_gender(dataset)
    process_age(dataset)
    process_year_of_record(dataset)
    process_profession(dataset)
    process_university_degree(dataset)
    process_hair_color(dataset)
    process_housing(dataset)
    process_satisfaction(dataset)
    process_exp(dataset)
    return dataset

data_processed = preprocess_dataset(data)

data_processed.dtypes

def convert_to_int(dataset,col):
  dataset[col] = dataset[col].astype(float)
  return dataset

data_processed['Yearly Income in addition to Salary (e.g. Rental Income)']= data_processed['Yearly Income in addition to Salary (e.g. Rental Income)'].map(lambda st:st.split(' ')[0])
data_processed = convert_to_int(data_processed,'Yearly Income in addition to Salary (e.g. Rental Income)')
data_processed = convert_to_int(data_processed,'Work Experience in Current Job [years]')

data_processed = convert_to_int(data_processed,'Total Yearly Income [EUR]')

def get_mean_rank(df,col):
  df1 = df.groupby([col])['Total Yearly Income [EUR]'].mean().sort_values()
  dict_rank = {}
  counter = 1
  for row in  df1.iteritems():
    dict_rank[row[0]] = counter
    counter+=1
  return dict_rank

dict_profession = get_mean_rank(data_processed,'Profession')

dict_year = get_mean_rank(data_processed,'Year of Record')

dict_country = get_mean_rank(data_processed,"Country")

from sklearn.preprocessing import LabelEncoder
for col in data_processed.dtypes[data_processed.dtypes == 'object'].index.tolist():
    if col in ['Profession','Country']:
      continue
    else:
      feat_le = LabelEncoder()
      feat_le.fit(data_processed[col].unique().astype(str))
      data_processed[col] = feat_le.transform(data_processed[col].astype(str))

data_processed['Profession'] = data_processed['Profession'].map(dict_profession)
data_processed['Year of Record'] = data_processed['Year of Record'].map(dict_year)
data_processed['Country'] = data_processed['Country'].map(dict_country)

data_processed.columns



from sklearn.model_selection import train_test_split
X_train,X_test = data_processed.iloc[:1048574],data_processed.iloc[1048574:]
X_train['Total Yearly Income [EUR]'] = X_train['Total Yearly Income [EUR]'] - X_train['Yearly Income in addition to Salary (e.g. Rental Income)']
Y_train = data_processed['Total Yearly Income [EUR]'].iloc[:1048574]
X_test_id = data_processed['Instance'].iloc[1048574:]
train_rental = X_train['Yearly Income in addition to Salary (e.g. Rental Income)']
test_rental = X_test['Yearly Income in addition to Salary (e.g. Rental Income)']
X_train.drop(['Total Yearly Income [EUR]','Instance','Yearly Income in addition to Salary (e.g. Rental Income)'],axis=1,inplace=True)
X_test.drop(['Total Yearly Income [EUR]','Instance','Yearly Income in addition to Salary (e.g. Rental Income)'],axis=1,inplace=True)
x_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.2,random_state=1234)

y_train = np.log(y_train)
y_val = np.log(y_val)

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()

##### 7. transform y ###############
y_train_log = np.log(y_train)
###################################

###### 8. fit model and predict the income ###############
regressor.fit(x_train, y_train_log)
y_pred_lin = np.exp(regressor.predict(x_val))

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_val,y_pred_lin)

import lightgbm as lgb
model_lgb = lgb.LGBMRegressor(objective='regression_l1',boosting="gbdt", num_leaves=70, n_estimators=1500)
model_lgb.fit(x_train, y_train_log)

y_pred = np.exp(model_lgb.predict(x_val))

mean_absolute_error(y_val,y_pred)

import lightgbm as lgb
params = {
          'max_depth': 20,
          'learning_rate': 0.01,
          "boosting": "gbdt",
          "bagging_seed": 11,
          "metric": 'mae',
          "verbosity": -1
         }
trn_data = lgb.Dataset(x_train, label=y_train_log)
val_data = lgb.Dataset(x_val, label=np.log(y_val))
# test_data = lgb.Dataset(X_test)
clf = lgb.train(params, trn_data, 50000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)

lgb_pred = np.exp(clf.predict(x_val))

mean_absolute_error(lgb_pred,y_val)

predict = clf.predict(X_test)

parameters = {'nthread':[4], 
              'objective':['reg:squarederror'],
                   'min_child_weight': [5],
        'gamma': [0.5],
        'subsample': [0.8],
        'colsample_bytree': [1.0],
        'max_depth': [11]}

import re
regex = re.compile(r"\[|\]|<", re.IGNORECASE)
x_train.columns = [regex.sub("_", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_train.columns.values]

import re
regex = re.compile(r"\[|\]|<", re.IGNORECASE)
x_val.columns = [regex.sub("_", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]

from sklearn.preprocessing import LabelEncoder
import xgboost
from sklearn.metrics import mean_squared_error
xgb_model = xgboost.XGBRegressor(learning_rate =0.1, n_estimators=3000, nthread=6, scale_pos_weight=1, seed=27,tree_method='gpu_hist')

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = parameters, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_absolute_error')
gsearch1.fit(x_train,y_train_log)

xgb_pred = np.exp(gsearch1.predict(x_val))

mean_absolute_error(xgb_pred,y_val)

ensembled_prediction = (0.45*xgb_pred+0.55*lgb_pred)

mean_absolute_error(ensembled_prediction,y_val)

X_test.columns = [regex.sub("_", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test.columns.values]

xg_sub_pred = np.exp(gsearch1.predict( X_test))

ensembled_prediction = (0.40*xg_sub_pred+0.60*np.exp(predict))

sub_df = pd.DataFrame({'Instance':X_test_id,
                       'Total Yearly Income [EUR]':np.exp(predict)+test_rental})
sub_df.head()

sub_df.to_csv('sub_finallgb.csv')

xgb_thresh = [x for x in np.arange(0, 1, 0.05)]
lgb_thresh = [x for x in np.arange(0, 1, 0.05)]

score = 10000000
best_xgb = 0
best_lgb = 0
for x in xgb_thresh:
  for y in lgb_thresh:
    ensembled_prediction = (x*xgb_pred+y*lgb_pred)
    ensembeled_error = mean_absolute_error(y_val, ensembled_prediction)
    if ensembeled_error < score:
      score = ensembeled_error
      best_xgb = x
      best_lgb = y
      print(score)

x_val['Income'] = lgb_pred

x_val['true_income'] = y_val

train.loc[110509]

li = []

li2 = []

for row in x_val.iterrows():
  if (row[1]['true_income']-row[1]['Income']) >15000:
    li2.append(row[1]['true_income']-row[1]['Income'])

len(x_val)

df2 = pd.DataFrame(columns=train.columns)

len(li2)

df2['diff'] = li2

df5= df2.groupby(['Profession'])['diff'].mean().sort_values()

Professions = ['Audit Clerk'                       
'budget review specialist'          
'Baggage Handler'                  
'accountable project manager'       
'deputy budget director','ticket taker','crime analyst','timekeeper','desktop publisher','emergency field logistics coordinator','Baker']

df5[1180:]

years = [2011:2019]

Countries = ['Tanzania','Argentina','Bahamas','Morocco','Canada','Colombia','Mexico','Marshall Islands']

dict_country[0]

for i in range (len(x_val)):
  if x_val.iloc[i]['Country'] in Countries:
    print("here")
    lgb_pred[i]+=100000
  elif x_val.iloc[i]['Profession'] in Professions:
    lgb_pred[i]+=150000
  print(dict_country[x_val.iloc[i]['Country'])

pred = x_val['Income']

mean_absolute_error(lgb_pred,y_val)

df2.groupby('Country')['diff'].mean().sort_values()[140:]